{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Load Post-Processed Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/reviews_post_processing.pkl', 'rb') as f:\n",
    "    reviews = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_uppercase(text):\n",
    "    return sum(1 for char in text if char.isupper())\n",
    "\n",
    "def count_lowercase(text):\n",
    "    return sum(1 for char in text if char.islower())\n",
    "\n",
    "def count_punctuation(text):\n",
    "    return sum([1 for char in text if char in string.punctuation])\n",
    "\n",
    "def count_dots(text):\n",
    "    return sum([1 for char in text if char == '.'])\n",
    "\n",
    "def count_exclamation_marks(text):\n",
    "    return sum([1 for char in text if char == '!'])\n",
    "\n",
    "def count_question_marks(text):\n",
    "    return sum([1 for char in text if char == '?'])\n",
    "\n",
    "def count_digits(text):\n",
    "    return sum([1 for char in text if char.isdigit()])\n",
    "\n",
    "def count_stop_words(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return sum([1 for w in word_tokens if  w in stop_words])\n",
    "\n",
    "def count_sentiment_words(text, threshold=0.5):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    pos_word_list=[]\n",
    "    neu_word_list=[]\n",
    "    neg_word_list=[]\n",
    "    sentence_length = len(word_tokens)\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "    for word in word_tokens:\n",
    "        if (sid.polarity_scores(word)['compound']) >= threshold:\n",
    "            pos_word_list.append(word)\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -threshold:\n",
    "            neg_word_list.append(word)\n",
    "        else:\n",
    "            neu_word_list.append(word)\n",
    "    return len(pos_word_list)/sentence_length, len(neg_word_list)/sentence_length, len(neu_word_list)/sentence_length\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(text)\n",
    "    return tuple(ss.values())\n",
    "\n",
    "\n",
    "def calculate_lexical_diversity(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return len(set(word_tokens))/ len(word_tokens)\n",
    "\n",
    "def most_common_pos(text):\n",
    "    pos = nltk.pos_tag(word_tokenize(text))\n",
    "    return Counter([x[1] for x in pos]).most_common(3)\n",
    "\n",
    "def count_words(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return len(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = np.finfo(float).eps\n",
    "print('Word count')\n",
    "reviews['WordCount'] = reviews['Text'].agg(count_words)\n",
    "reviews['WordCountSummary'] = reviews['Summary'].agg(count_words)\n",
    "\n",
    "print('Stop words')\n",
    "reviews['StopWords'] = reviews['Text'].agg(count_stop_words)\n",
    "\n",
    "print('Uppercase')\n",
    "reviews['UpperCount'] = reviews['Text'].agg(count_uppercase)\n",
    "reviews['UpperCountSummary'] = reviews['Summary'].agg(count_uppercase)\n",
    "\n",
    "print('Lowercase')\n",
    "reviews['LowerCount'] = reviews['Text'].agg(count_lowercase)\n",
    "reviews['LowerCountSummary'] = reviews['Summary'].agg(count_lowercase)\n",
    "\n",
    "print('Dots')\n",
    "reviews['DotCount'] = reviews['Text'].agg(count_dots)\n",
    "reviews['DotCountSummary'] = reviews['Summary'].agg(count_dots)\n",
    "\n",
    "print('Exclamation')\n",
    "reviews['Exclamation'] = reviews['Text'].agg(count_exclamation_marks)\n",
    "reviews['ExclamationSummary'] = reviews['Summary'].agg(count_exclamation_marks)\n",
    "\n",
    "print('Question')\n",
    "reviews['Question'] = reviews['Text'].agg(count_question_marks)\n",
    "reviews['QuestionSummary'] = reviews['Summary'].agg(count_question_marks)\n",
    "\n",
    "print('Punctuation')\n",
    "reviews['CountPunctuation'] = reviews['Text'].agg(count_punctuation)\n",
    "reviews['CountPunctuationSummary'] = reviews['Summary'].agg(count_punctuation)\n",
    "\n",
    "print('Digits')\n",
    "reviews['CountDigits'] = reviews['Text'].agg(count_digits)\n",
    "reviews['CountDigitsSummary'] = reviews['Summary'].agg(count_digits)\n",
    "\n",
    "print('Lexical')\n",
    "reviews['Lexical'] = reviews['Text'].agg(calculate_lexical_diversity)\n",
    "reviews['LexicalSummary'] = reviews['Summary'].agg(calculate_lexical_diversity)\n",
    "\n",
    "print('Upper/Lower')\n",
    "reviews['UpperLowerR'] = reviews['UpperCount'] / (reviews['LowerCount'] + eps)\n",
    "reviews['UpperLowerSumR'] = reviews['UpperCountSummary'] / (reviews['LowerCountSummary'] + eps)\n",
    "\n",
    "print('Capital/dots')\n",
    "reviews['DotCapitalR'] = reviews['UpperCount'] / (reviews['DotCount'] + eps)\n",
    "reviews['DotCapitalSumR'] = reviews['UpperCountSummary'] / (reviews['DotCountSummary'] + eps)\n",
    "\n",
    "print('CapitalRatio')\n",
    "reviews['CapitalsRatio'] = reviews['UpperCount'] / (reviews['UpperCountSummary'] + eps)\n",
    "\n",
    "print('Get Reviews sentiment')\n",
    "reviews[['neg', 'neu', 'pos', 'compound']] = reviews['Text'].agg(sentiment_analysis).apply(pd.Series)\n",
    "\n",
    "print('Get log Features')\n",
    "reviews['ProductFreqlog'] = np.log2(reviews['ProductFrequency'])\n",
    "reviews['ReviewsbyReviewerlog'] = np.log2(reviews['Total_Reviews_by_Reviewer'])\n",
    "reviews['WordCountlog'] = np.log2(reviews['WordCount'])\n",
    "\n",
    "print('Timestamps')\n",
    "reviews['TimeStamp'] = pd.to_datetime(reviews.Time, unit='s')\n",
    "reviews['Year'] = reviews.TimeStamp.dt.year\n",
    "reviews['Month'] = reviews.TimeStamp.dt.month\n",
    "reviews['Day'] = reviews.TimeStamp.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/reviews_post_feature_eng.pkl', 'wb') as f:\n",
    "    pickle.dump(reviews ,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53480, 50), (18183, 50), (17471, 50))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('data/reviews_post_feature_eng.pkl', 'rb') as f:\n",
    "    reviews = pickle.load(f)\n",
    "\n",
    "reviews = reviews[reviews['HelpfullnessRank'] <=10]\n",
    "\n",
    "label = 'HelpfullnessRank'\n",
    "X = reviews.drop(label, axis=1)\n",
    "y = reviews[label]\n",
    "\n",
    "df_columns = X.columns\n",
    "\n",
    "\n",
    "# Split to train, test and validation datasets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.49)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/X_train',X_train)\n",
    "np.save('data/X_val', X_val)\n",
    "np.save('data/X_test', X_test)\n",
    "np.save('data/y_train', y_train)\n",
    "np.save('data/y_val', y_val)\n",
    "np.save('data/y_test', y_test)\n",
    "np.save('data/df_cols', df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
