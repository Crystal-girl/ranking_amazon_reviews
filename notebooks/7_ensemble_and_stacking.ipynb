{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load probas:\n",
    "import pickle\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = 'data/proba/'\n",
    "\n",
    "# Feature eng:\n",
    "xgb_fe_val_proba = pickle.load(open(path + 'xgb_fe_val_proba.pkl', 'rb'))    # dimmention verified\n",
    "xgb_fe_train_proba = pickle.load(open(path + 'xgb_fe_train_proba.pkl', 'rb')) # dimmention verified\n",
    "xgb_fe_test_proba = pickle.load(open(path + 'xgb_fe_test_proba.pkl', 'rb')) # dimmention verified\n",
    "\n",
    "svm_fe_train_proba = pickle.load(open(path + 'svm_fe_train_proba.pkl', 'rb')) # dimmention verified\n",
    "svm_fe_val_proba =  pickle.load(open(path + 'svm_fe_val_proba.pkl', 'rb'))    # dimmention verified\n",
    "svm_fe_test_proba =  pickle.load(open(path +  'svm_fe_test_proba.pkl', 'rb')) # dimmention verified\n",
    "\n",
    "rfc_fe_val_proba = pickle.load(open(path + 'rfc_fe_val_proba.pkl', 'rb'))     # dimmention verified\n",
    "rfc_fe_train_proba = pickle.load(open(path + 'rfc_fe_train_proba.pkl', 'rb')) # dimmention verified\n",
    "rfc_fe_test_proba = pickle.load(open(path + 'rfc_fe_test_proba.pkl', 'rb'))   # dimmention verified\n",
    "\n",
    "# Bag of words:\n",
    "rfc_bow_val_proba = pickle.load(open(path + 'rfc_bow_val_proba.pkl', 'rb'))      # dimmention verified\n",
    "rfc_bow_test_proba = pickle.load(open(path + 'rfc_bow_test_proba.pkl', 'rb'))    # dimmention verified\n",
    "rfc_bow_train_proba = pickle.load(open(path +  'rfc_bow_train_proba.pkl', 'rb')) # dimmention verified\n",
    "\n",
    "xgb_bow_train_proba = pickle.load(open(path + 'xgb_bow_train_proba.pkl', 'rb')) #  bad dim (50,12)\n",
    "xgb_bow_test_proba = pickle.load(open(path +  'xgb_bow_test_proba.pkl', 'rb'))\n",
    "xgb_bow_val_proba =  pickle.load(open(path + 'xgb_bow_val_proba.pkl', 'rb'))\n",
    "\n",
    "# tfidf\n",
    "rfc_tfidf_train_proba = pickle.load(open(path +  'rfc_tfidf_train_proba.pkl', 'rb')) # dimmention verified\n",
    "rfc_tfidf_test_proba =  pickle.load(open(path +  'rfc_tfidf_test_proba.pkl', 'rb'))  # dimmention verified\n",
    "rfc_tfidf_val_proba =  pickle.load(open(path +  'rfc_tfidf_val_proba.pkl', 'rb'))    # dimmention verified\n",
    "\n",
    "xgb_tfidf_test_proba = pickle.load(open(path + 'xgb_tfidf_test_proba.pkl', 'rb')) # bad dim (50,12)\n",
    "xgb_tfidf_val_proba = pickle.load(open(path + 'xgb_tfidf_val_proba.pkl', 'rb'))\n",
    "xgb_tfidf_train_proba = pickle.load(open(path + 'xgb_tfidf_train_proba.pkl', 'rb'))\n",
    "\n",
    "y_test = np.load('data/y_test.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "y_val = np.load('data/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save predictions (for ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_prediction(proba, y):\n",
    "    \"\"\"\n",
    "    Gets a list of prediction probabilities matrices and calcuate their confidance values\n",
    "    \n",
    "    Args:\n",
    "        proba(np.array): the predictions probability matrices (np.array)\n",
    "         y(np.array): labels (groud truth)\n",
    "    Returns:\n",
    "        (np.array). a list of confidance values (accuracy score)\n",
    "    \"\"\"\n",
    "       \n",
    "    prediction = proba.argmax(axis=1)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_probas =[xgb_fe_train_proba, svm_fe_train_proba, rfc_fe_train_proba, \n",
    "               rfc_bow_train_proba, xgb_bow_train_proba, rfc_tfidf_train_proba, \n",
    "               xgb_tfidf_train_proba]\n",
    "\n",
    "val_probas =[xgb_fe_val_proba, svm_fe_val_proba, rfc_fe_val_proba, \n",
    "               rfc_bow_val_proba, xgb_bow_val_proba, rfc_tfidf_val_proba, \n",
    "               xgb_tfidf_val_proba]\n",
    "\n",
    "test_probas =[xgb_fe_test_proba, svm_fe_test_proba, rfc_fe_test_proba, \n",
    "               rfc_bow_test_proba, xgb_bow_test_proba, rfc_tfidf_test_proba, \n",
    "               xgb_tfidf_test_proba]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_fe_val_pred = retrieve_prediction(xgb_fe_val_proba, y_val)\n",
    "svm_fe_val_pred = retrieve_prediction(svm_fe_val_proba, y_val)\n",
    "rfc_fe_val_pred = retrieve_prediction(rfc_fe_val_proba, y_val)\n",
    "rfc_bow_val_pred = retrieve_prediction(rfc_bow_val_proba, y_val)\n",
    "xgb_bow_val_pred = retrieve_prediction(xgb_bow_val_proba, y_val)\n",
    "rfc_tfidf_val_pred = retrieve_prediction(rfc_tfidf_val_proba, y_val)\n",
    "xgb_tfidf_val_pred = retrieve_prediction(xgb_tfidf_val_proba, y_val)\n",
    "\n",
    "np.save('xgb_fe_val_pred.npy', xgb_fe_val_pred)\n",
    "np.save('svm_fe_val_pred.npy', svm_fe_val_pred)\n",
    "np.save('rfc_fe_val_pred.npy', rfc_fe_val_pred)\n",
    "np.save('xgb_fe_val_pred.npy', xgb_fe_val_pred)\n",
    "np.save('rfc_bow_val_pred.npy', rfc_bow_val_pred)\n",
    "np.save('xgb_bow_val_pred.npy', xgb_bow_val_pred)\n",
    "np.save('rfc_tfidf_val_pred.npy', rfc_tfidf_val_pred)\n",
    "np.save('xgb_tfidf_val_pred.npy', xgb_tfidf_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensenble methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def equally_ebsemble_results(predictions_probas):\n",
    "    \"\"\"\n",
    "    Ensbale prediction result with equal weight\n",
    "    \n",
    "    Args:\n",
    "        predictions_probas(list): A list of the predictions probability matrices (np.array)\n",
    "    \n",
    "    Returns:\n",
    "        np.array. The predictions for the equally ensambled models\n",
    "    \"\"\"\n",
    "    sum_predictions_prob = np.zeros(predictions_probas[0].shape)\n",
    "    \n",
    "    for curr_pred in predictions_probas:\n",
    "        sum_predictions_prob += curr_pred\n",
    "    \n",
    "    ensemble_prob = np.divide(sum_predictions_prob, len(predictions_probas))\n",
    "        \n",
    "    return np.argmax(ensemble_prob, axis=1)\n",
    "\n",
    "\n",
    "def calculate_confidance_val(predictions_probas, y):\n",
    "    \"\"\"\n",
    "    Gets a list of prediction probabilities matrices and calcuate their confidance values\n",
    "    \n",
    "    Args:\n",
    "         predictions_probas(list): A list of the predictions probability matrices (np.array)\n",
    "         y(np.array): labels (groud truth)\n",
    "    Returns:\n",
    "        (list). a list of confidance values (accuracy score)\n",
    "    \"\"\"\n",
    "    confidance_values = []\n",
    "    \n",
    "    for proba in predictions_probas:\n",
    "        prediction = proba.argmax(axis=1)\n",
    "        confidance_values.append(accuracy_score(y, prediction))\n",
    "    \n",
    "    return confidance_values\n",
    "    \n",
    "    \n",
    "def weighted_ebsemble_results(predictions_probas, confidance_values):\n",
    "    \"\"\"\n",
    "    Ensbale prediction result with weight according to each model confidance value\n",
    "    \n",
    "    Args:\n",
    "        predictions_probas(list): A list of the predictions probability matrices (np.array)\n",
    "    \n",
    "    Returns:\n",
    "        np.array. The predictions for the equally ensambled models\n",
    "    \"\"\"\n",
    "    sum_predictions_prob = np.zeros(predictions_probas[0].shape)\n",
    "    \n",
    "    for curr_pred, w in zip(predictions_probas, confidance_values):\n",
    "        sum_predictions_prob += w * curr_pred\n",
    "    \n",
    "    ensemble_prob = np.divide(sum_predictions_prob, sum(confidance_values))\n",
    "        \n",
    "    return np.argmax(ensemble_prob, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def stack_probas(predict_probas):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for ind, curr_predic_proba in enumerate(predict_probas):\n",
    "        if ind == 0:\n",
    "            stacked_proba = curr_predic_proba\n",
    "        else:\n",
    "            stacked_proba = np.concatenate((stacked_proba, curr_predic_proba), axis=1)\n",
    "    return stacked_proba\n",
    "\n",
    "def stack_models(train_probas, val_probas, y_train, y_val, estimator, test_probas=None, y_test=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    stacked_proba_train = stack_probas(train_probas)\n",
    "    stacked_proba_val = stack_probas(val_probas)\n",
    "   \n",
    "    \n",
    "    model = estimator\n",
    "    \n",
    "    model.fit(stacked_proba_train, y_train)\n",
    "    \n",
    "    stacked_train_pred = model.predict(stacked_proba_train)\n",
    "    stacked_val_pred = model.predict(stacked_proba_val)\n",
    "    \n",
    "    train_accuracy = accuracy_score(stacked_train_pred, y_train)\n",
    "    val_accuracy = accuracy_score(stacked_val_pred, y_val)\n",
    "    \n",
    "    if y_test.any():\n",
    "        stacked_proba_test = stack_probas(test_probas)\n",
    "        stacked_test_pred = model.predict(stacked_proba_test)\n",
    "        test_accuracy = accuracy_score(y_test,stacked_test_pred)\n",
    "    else:\n",
    "        test_accuracy = None\n",
    "        \n",
    "    return (train_accuracy, val_accuracy, test_accuracy), stacked_train_pred, stacked_val_pred, stacked_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equally weighted ensemble:\n",
      "--------------------------\n",
      "Train accuracy:  0.9975317875841436\n",
      "Val accuracy:  0.6653311201419495\n",
      "Test accuracy:  0.6696364736292141\n"
     ]
    }
   ],
   "source": [
    "# Equaly wiegthed ensamble:\n",
    "train_eq_ensemble_pred = equally_ebsemble_results(train_probas)\n",
    "val_eq_ensemble_pred = equally_ebsemble_results(val_probas)\n",
    "test_eq_ensemble_pred = equally_ebsemble_results(test_probas)\n",
    "\n",
    "print(\"Equally weighted ensemble:\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, train_eq_ensemble_pred))\n",
    "print(\"Val accuracy: \", accuracy_score(y_val, val_eq_ensemble_pred))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, test_eq_ensemble_pred))\n",
    "\n",
    "np.save('train_eq_ensemble_pred.npy',train_eq_ensemble_pred)\n",
    "np.save('val_eq_ensemble_pred.npy',val_eq_ensemble_pred)\n",
    "np.save('test_eq_ensemble_pred.npy',test_eq_ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted ensemble:\n",
      "--------------------------\n",
      "Train accuracy:  0.9975317875841436\n",
      "Val accuracy:  0.6653311201419495\n",
      "Test accuracy:  0.6696364736292141\n"
     ]
    }
   ],
   "source": [
    "# Equaly wiegthed ensamble:\n",
    "cofidance_train = calculate_confidance_val(train_probas, y_train)\n",
    "cofidance_val = calculate_confidance_val(val_probas, y_val)\n",
    "cofidance_test = calculate_confidance_val(test_probas, y_test)\n",
    "\n",
    "train_w_ensemble_pred = weighted_ebsemble_results(train_probas, cofidance_train )\n",
    "val_w_ensemble_pred = weighted_ebsemble_results(val_probas,cofidance_val )\n",
    "test_w_ensemble_pred = weighted_ebsemble_results(test_probas, cofidance_test)\n",
    "\n",
    "print(\"Weighted ensemble:\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, train_eq_ensemble_pred))\n",
    "print(\"Val accuracy: \", accuracy_score(y_val, val_eq_ensemble_pred))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, test_eq_ensemble_pred))\n",
    "\n",
    "np.save('train_w_ensemble_pred.npy',train_w_ensemble_pred)\n",
    "np.save('val_w_ensemble_pred.npy',val_w_ensemble_pred)\n",
    "np.save('test_w_ensemble_pred.npy',test_w_ensemble_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=50)\n",
    "\n",
    "stacking_accuracy_logreg, train_stack_logreg_pred, val_stack_logreg_pred, test_stack_logreg_pred =  \\\n",
    "                stack_models(train_probas, val_probas, y_train, y_val,logreg, test_probas, y_test)\n",
    "    \n",
    "stacking_accuracy_rfc, train_stack_rfc_pred, val_stack_rfc_pred, test_stack_rfc_pred =  \\\n",
    "                stack_models(train_probas, val_probas, y_train, y_val, rfc, test_probas, y_test)\n",
    "    \n",
    "np.save('train_stack_logreg_pred.npy',train_stack_logreg_pred)\n",
    "np.save('val_stack_logreg_pred.npy',val_stack_logreg_pred)\n",
    "np.save('test_stack_logreg_pred.npy',test_stack_logreg_pred)\n",
    "\n",
    "np.save('train_stack_rfc_pred.npy',train_stack_logreg_pred)\n",
    "np.save('val_stack_rfc_pred.npy',val_stack_logreg_pred)\n",
    "np.save('test_stack_rfc_pred.npy',test_stack_logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9979618548990277, 0.6687653826340794, 0.6727712698674586),\n",
       " (0.9979618548990277, 0.6582336443248812, 0.661826981246219))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_accuracy_logreg, stacking_accuracy_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "\n",
    "# stacking_accuracy_logreg, train_stack_pred, val_stack_pred, test_stack_pred =  \\\n",
    "#                 stack_models(train_probas, val_probas, y_train, y_val,logreg, test_probas, y_test)\n",
    "    \n",
    "stacking_accuracy_rfc, train_stack_pred, val_stack_pred, test_stack_pred =  \\\n",
    "                stack_models(train_probas, val_probas, y_train, y_val, rfc, test_probas, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9979992520568437, 0.6666475874305993, 0.6690865093768905)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_accuracy_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
